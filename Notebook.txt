import json

# Read the contents of images.txt
with open('images.txt', 'r') as file:
    content = file.read().strip()

# Process the content and create the matrix JSON data
lines = content.split('\n')
image_list = []
for line in lines:
    parts = line.strip().split(':')
    image_list.append({
        'image': parts[0],
        'version': parts[1]
    })

matrix_data = {
    'include': image_list
}
matrix_output = json.dumps(matrix_data)

# Output the matrix data to $GITHUB_OUTPUT
with open('$GITHUB_OUTPUT', 'w') as output_file:
    output_file.write(matrix_output)




name: Docker Image Processing

on:
  push:
    branches:
      - main

jobs:
  prepare-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.x

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Read and process images.txt
        id: set-matrix
        run: python prepare_matrix.py

  process-images:
    needs: prepare-matrix
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.prepare-matrix.outputs.matrix) }}

    steps:
      - name: Set up Snyk
        uses: snyk/actions/setup@master
        with:
          token: ${{ secrets.SNYK_TOKEN }}

      - name: Run script for each image
        run: |
          ./your-shell-script.sh -i ${{ matrix.image }}:${{ matrix.version }} --scanTool snyk
